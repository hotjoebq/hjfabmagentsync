{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b62e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Agent System with Azure AI and Microsoft Fabric\n",
    "# PRODUCTION-SAFE VERSION - Uses environment variables for all sensitive data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec0dcc",
   "metadata": {},
   "source": [
    "#### Install required libraries\n",
    "Install necessary python packages for the multi-agent system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab12a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install semantic-kernel azure-ai-projects azure-identity azure-mgmt-resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6bf5b0",
   "metadata": {},
   "source": [
    "#### Import dependencies\n",
    "Import needed modules for Azure AI, Fabric, and Semantic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08666b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fabric utilities\n",
    "notebookutils.fs.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e8cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HJ: \", notebookutils.fs.ls(\"/./\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebookutils.fs.mounts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabf23d8",
   "metadata": {},
   "source": [
    "### Sets up Azure credentials and initializes the AI project client.\n",
    "**SECURITY NOTE**: This cell uses environment variables for sensitive information.\n",
    "Set these environment variables before running:\n",
    "- AZURE_TENANT_ID\n",
    "- AZURE_CLIENT_ID  \n",
    "- AZURE_CLIENT_SECRET\n",
    "- AZURE_PROJECT_CONNECTION_STRING\n",
    "- AZURE_MODEL_DEPLOYMENT_NAME\n",
    "- FABRIC_BASE_URL\n",
    "- ML_DATA_PATH\n",
    "- ML_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.mgmt.resource import SubscriptionClient\n",
    "\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Dict\n",
    "from pprint import pprint\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai._models import FinalRequestOptions\n",
    "from openai._types import Omit\n",
    "from openai._utils import is_given\n",
    "from synapse.ml.mlflow import get_mlflow_env_config\n",
    "\n",
    "from azure.identity import ClientSecretCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import AzureAISearchTool, FunctionTool, RequiredFunctionToolCall, SubmitToolOutputsAction, ToolOutput\n",
    "\n",
    "from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "# Load credentials from environment variables for security\n",
    "credential = ClientSecretCredential(\n",
    "    tenant_id=os.environ.get(\"AZURE_TENANT_ID\"),\n",
    "    client_id=os.environ.get(\"AZURE_CLIENT_ID\"),\n",
    "    client_secret=os.environ.get(\"AZURE_CLIENT_SECRET\"),\n",
    ")\n",
    "\n",
    "# Load configuration from environment variables\n",
    "project_connection_string = os.environ.get(\"AZURE_PROJECT_CONNECTION_STRING\")\n",
    "model_deployment_name = os.environ.get(\"AZURE_MODEL_DEPLOYMENT_NAME\", \"hjfab-gpt-4o\")\n",
    "\n",
    "# Validate required environment variables\n",
    "required_vars = [\n",
    "    \"AZURE_TENANT_ID\", \"AZURE_CLIENT_ID\", \"AZURE_CLIENT_SECRET\", \n",
    "    \"AZURE_PROJECT_CONNECTION_STRING\", \"FABRIC_BASE_URL\"\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not os.environ.get(var)]\n",
    "if missing_vars:\n",
    "    raise ValueError(f\"Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=credential,\n",
    "    conn_str=project_connection_string\n",
    ")\n",
    "\n",
    "print(\"Testing Azure credentials...\")\n",
    "try:\n",
    "    subscription_client = SubscriptionClient(credential)\n",
    "    subscriptions = list(subscription_client.subscriptions.list())\n",
    "    print(\"✅ Successfully authenticated. Available subscriptions:\")\n",
    "    for sub in subscriptions:\n",
    "        print(f\"- {sub.subscription_id}: {sub.display_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Authentication failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba12b8",
   "metadata": {},
   "source": [
    "### Returning all the connections in the project in AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee745e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = project_client.connections.list()\n",
    "for connection in connections:\n",
    "    print(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2404828b",
   "metadata": {},
   "source": [
    "### Returning just the AI Search connection in the project in AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c56aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import Evaluation, Dataset, EvaluatorConfiguration, ConnectionType\n",
    "\n",
    "connections = project_client.connections.list(\n",
    "    connection_type=ConnectionType.AZURE_AI_SEARCH,\n",
    ")\n",
    "search_connection_id = \"\"\n",
    "search_connection_name = os.environ.get(\"AZURE_SEARCH_CONNECTION_NAME\", \"AzureAISearch\")\n",
    "\n",
    "for connection in connections:\n",
    "    print(\"The connection name: \", connection.name)\n",
    "    if connection.name == search_connection_name:\n",
    "        search_connection_id = connection.id\n",
    "        print(f\"✅ Found search connection: {connection.name}\")\n",
    "        break\n",
    "\n",
    "if not search_connection_id:\n",
    "    print(f\"⚠️ Search connection '{search_connection_name}' not found\")\n",
    "    \n",
    "print(\"Connection ID for Search: \", search_connection_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002caef1",
   "metadata": {},
   "source": [
    "#### Create an AI agent\n",
    "Creates an agent, the tools, the definitions and plugin in the class if it comes from the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f733ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_agent(\n",
    "    client,\n",
    "    name,\n",
    "    instructions,\n",
    "    tools=None,\n",
    "    tool_resources=None,\n",
    "    plugins=None,  # <- Optional Parameter\n",
    "    model=None     # <- To override models for agents if needed.\n",
    "):\n",
    "    agent_definition = await client.agents.create_agent(\n",
    "        model=model or model_deployment_name,\n",
    "        name=name,\n",
    "        instructions=instructions,\n",
    "        tools=tools,\n",
    "        tool_resources=tool_resources,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"},\n",
    "    )\n",
    "\n",
    "    return AzureAIAgent(\n",
    "        client=client,\n",
    "        definition=agent_definition,\n",
    "        plugins=plugins  # <- Created in the class if receive from request\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79ec24",
   "metadata": {},
   "source": [
    "### This class is used as a utility to connect to the Data Agent with a query\n",
    "**SECURITY NOTE**: The base_url is loaded from environment variables.\n",
    "FABRIC_BASE_URL environment variable must be set with your Fabric workspace URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e04649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import typing as t\n",
    "from openai import OpenAI\n",
    "from openai._exceptions import APIStatusError\n",
    "from sempy.fabric._token_provider import SynapseTokenProvider\n",
    "\n",
    "# Load Fabric URL from environment variable\n",
    "base_url = os.environ.get(\"FABRIC_BASE_URL\")\n",
    "if not base_url:\n",
    "    raise ValueError(\"FABRIC_BASE_URL environment variable is required\")\n",
    "\n",
    "question = \"What datasources do you have access to?\"\n",
    "configs = get_mlflow_env_config()\n",
    "\n",
    "# Create OpenAI Client for Fabric\n",
    "class HJFabricOpenAI(OpenAI):\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_version: str = \"2024-05-01-preview\",\n",
    "        **kwargs: t.Any,\n",
    "    ) -> None:\n",
    "        self.api_version = api_version\n",
    "        default_query = kwargs.pop(\"default_query\", {})\n",
    "        default_query[\"api-version\"] = self.api_version\n",
    "        super().__init__(\n",
    "            api_key=\"\",\n",
    "            base_url=base_url,\n",
    "            default_query=default_query,\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "    def _prepare_options(self, options: FinalRequestOptions) -> None:\n",
    "        headers: dict[str, str | Omit] = (\n",
    "            {**options.headers} if is_given(options.headers) else {}\n",
    "        )\n",
    "        options.headers = headers\n",
    "        headers[\"Authorization\"] = f\"Bearer {configs.driver_aad_token}\"\n",
    "        if \"Accept\" not in headers:\n",
    "            headers[\"Accept\"] = \"application/json\"\n",
    "        if \"ActivityId\" not in headers:\n",
    "            correlation_id = str(uuid.uuid4())\n",
    "            headers[\"ActivityId\"] = correlation_id\n",
    "\n",
    "        return super()._prepare_options(options)\n",
    "\n",
    "# Pretty printing helper\n",
    "def pretty_print(messages):\n",
    "    print(\"---Conversation---\")\n",
    "    for m in messages:\n",
    "        print(f\"{m.role}: {m.content[0].text.value}\")\n",
    "    print()\n",
    "\n",
    "print(\"Testing Fabric Data Agent connection...\")\n",
    "try:\n",
    "    fabric_client = HJFabricOpenAI()\n",
    "    assistant = fabric_client.beta.assistants.create(model=\"not used\")\n",
    "    thread = fabric_client.beta.threads.create()\n",
    "    message = fabric_client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=question)\n",
    "    run = fabric_client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id)\n",
    "\n",
    "    # Wait for completion\n",
    "    while run.status in [\"queued\", \"in_progress\"]:\n",
    "        run = fabric_client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        time.sleep(2)\n",
    "\n",
    "    response = fabric_client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")\n",
    "    pretty_print(response)\n",
    "    fabric_client.beta.threads.delete(thread_id=thread.id)\n",
    "    print(\"✅ Fabric Data Agent connection successful\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Fabric Data Agent connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f109a13",
   "metadata": {},
   "source": [
    "### Implements a custom Data Agent for retrieving customer information using Fabric AI.\n",
    "This class is designed to be a Function Tool, which interacts with Fabric to retrieve customer-related information.\n",
    "**SECURITY NOTE**: This class loads the Fabric base URL from environment variables for security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f662850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FabricFunctionAISkill:\n",
    "    @kernel_function(description=\"Provides information such as age and tenure about clients.\")\n",
    "    def call_fabric_ai_skill(self, question: str) -> str:\n",
    "        print(\"Calling Fabric AI Skill with question:\", question)\n",
    "        configs = get_mlflow_env_config()\n",
    "        \n",
    "        # Load base URL from environment variable\n",
    "        base_url = os.environ.get(\"FABRIC_BASE_URL\")\n",
    "        if not base_url:\n",
    "            raise ValueError(\"FABRIC_BASE_URL environment variable is required\")\n",
    "\n",
    "        class FabricOpenAI(OpenAI):\n",
    "            def __init__(self, api_version: str = \"2024-05-01-preview\", **kwargs: Any) -> None:\n",
    "                self.api_version = api_version\n",
    "                default_query = kwargs.pop(\"default_query\", {})\n",
    "                default_query[\"api-version\"] = self.api_version\n",
    "                super().__init__(api_key=\"\", base_url=base_url, default_query=default_query, **kwargs)\n",
    "\n",
    "            def _prepare_options(self, options: FinalRequestOptions) -> None:\n",
    "                headers: Dict[str, str | Omit] = {**options.headers} if is_given(options.headers) else {}\n",
    "                headers[\"Authorization\"] = f\"Bearer {configs.driver_aad_token}\"\n",
    "                headers.setdefault(\"Accept\", \"application/json\")\n",
    "                headers.setdefault(\"ActivityId\", str(uuid.uuid4()))\n",
    "                options.headers = headers\n",
    "                return super()._prepare_options(options)\n",
    "\n",
    "        try:\n",
    "            fabric_client = FabricOpenAI()\n",
    "            assistant = fabric_client.beta.assistants.create(model=\"not used\")\n",
    "            thread = fabric_client.beta.threads.create()\n",
    "            fabric_client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=question)\n",
    "            run = fabric_client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id)\n",
    "\n",
    "            while run.status in [\"queued\", \"in_progress\"]:\n",
    "                run = fabric_client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "                time.sleep(2)\n",
    "\n",
    "            response = fabric_client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")\n",
    "            answer = next((m.content[0].text.value for m in response if m.role == \"assistant\"), None)\n",
    "            fabric_client.beta.threads.delete(thread_id=thread.id)\n",
    "            \n",
    "            return json.dumps({\"answer\": answer if answer else \"No response from Fabric Data Agent.\"})\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Fabric AI Skill: {e}\")\n",
    "            return json.dumps({\"answer\": f\"Error: {str(e)}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c699a78",
   "metadata": {},
   "source": [
    "### Implements a custom Data Agent for predicting customer churn using MLFlow.\n",
    "This class demonstrates the use of SynapseML for predictions and interacts with MLFlow to predict customer churn.\n",
    "**SECURITY NOTE**: Data paths and model names are configurable via environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85db071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from typing import Any, Dict\n",
    "from pyspark.sql import SparkSession\n",
    "from mlflow import pyfunc\n",
    "\n",
    "class FabricFunctionML:\n",
    "    @kernel_function(description=\"Predicts which customers will become a churn\")\n",
    "    def call_ML_model(self, question: str) -> str:\n",
    "        print(\"Loading ML model for churn prediction...\")\n",
    "       \n",
    "        # Load configuration from environment variables\n",
    "        data_path = os.environ.get(\"ML_DATA_PATH\")\n",
    "        model_name = os.environ.get(\"ML_MODEL_NAME\", \"hj_lgbm_sm\")\n",
    "        model_version = os.environ.get(\"ML_MODEL_VERSION\", \"1\")\n",
    "        \n",
    "        if not data_path:\n",
    "            raise ValueError(\"ML_DATA_PATH environment variable is required\")\n",
    "\n",
    "        try:\n",
    "            print(f\"Loading data from: {data_path}\")\n",
    "            df_test = spark.read.format(\"delta\").load(data_path)\n",
    "            \n",
    "            print(f\"Loading model: {model_name} version {model_version}\")\n",
    "            model = pyfunc.load_model(f\"models:/{model_name}/{model_version}\")\n",
    "            \n",
    "            print(\"Making predictions...\")\n",
    "            predictions = model.predict(df_test.toPandas())\n",
    "            \n",
    "            # Convert predictions to JSON\n",
    "            answer = json.dumps(predictions.tolist())\n",
    "            print(\"✅ ML prediction completed successfully\")\n",
    "            \n",
    "            return json.dumps({\"answer\": answer if answer else \"No response from ML.\"})\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in ML model: {e}\")\n",
    "            return json.dumps({\"answer\": f\"Error: {str(e)}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217cacf",
   "metadata": {},
   "source": [
    "### Sets up various agents and defines their roles.\n",
    "Creates routing agent, synthesis agent, customer info agent, churn prediction agent, loyalty programs agent, and chit-chat agent.\n",
    "**SECURITY NOTE**: All connection strings and sensitive configuration loaded from environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize plugins\n",
    "AISKill_plugin = FabricFunctionAISkill()\n",
    "FabricML_plugin = FabricFunctionML()\n",
    "\n",
    "print(\"Creating Azure AI Agent client...\")\n",
    "sk_client = AzureAIAgent.create_client(\n",
    "    credential=credential,\n",
    "    conn_str=project_connection_string\n",
    ")\n",
    "\n",
    "print(\"Creating thread for agents...\")\n",
    "thread = await sk_client.agents.create_thread()\n",
    "\n",
    "# Coordinator agents\n",
    "router_instructions = (\n",
    "    \"You are a routing coordinator. Your only task is to route the user query to the correct agents by generating a JSON object. \"\n",
    "    \"The JSON should map agent names to sub-queries. \"\n",
    "    \"The valid agents are: \"\n",
    "    \"- CustomerInfoAgent: Handles questions related to data and customer information. \"\n",
    "    \"- LoyaltyProgramsAgent: Expert in Loyalty Programs. \"\n",
    "    \"- ChitChatAgent: Handles informal, social, or general-purpose questions. \"\n",
    "    \"- ChurnPredAgent: Predicts customer churn. \"\n",
    "    \"IMPORTANT: Do not answer the user's question yourself. ONLY return a valid JSON object mapping the agents to sub-queries. \"\n",
    "    \"Example: {\\\"CustomerInfoAgent\\\": \\\"What data sources are available?\\\", \\\"ChurnPredAgent\\\": \\\"Predict churn for customer 123\\\"} \"\n",
    "    \"If none of the agents are a good match, route the full question to ChitChatAgent as fallback. \"\n",
    "    \"Never include explanations, comments, or assistant-like messages.\"\n",
    ")\n",
    "\n",
    "print(\"Creating routing agent...\")\n",
    "routing_agent = await create_agent(\n",
    "    sk_client,\n",
    "    \"RoutingAgent\",\n",
    "    router_instructions\n",
    ")\n",
    "\n",
    "print(\"Creating synthesis agent...\")\n",
    "synthesis_agent = await create_agent(\n",
    "    sk_client,\n",
    "    \"SynthesisAgent\",\n",
    "    \"You are a synthesis agent. Combine responses from other agents into a clear, friendly answer. Don't include any JSON.\"\n",
    ")\n",
    "\n",
    "# Customer Info Agent with Fabric AI Skill\n",
    "print(\"Creating customer info agent...\")\n",
    "functions = FunctionTool(functions={FabricFunctionAISkill.call_fabric_ai_skill})\n",
    "CustomerAgent = await create_agent(\n",
    "    sk_client,\n",
    "    \"CustomerInfoAgent\",\n",
    "    \"You are responsible for answering customer-related questions using an internal Data Agent. Please, try to use your tool any time you receive a question.\",\n",
    "    tools=functions.definitions,\n",
    "    plugins=[AISKill_plugin]\n",
    ")\n",
    "\n",
    "# Churn Prediction Agent with ML Model\n",
    "print(\"Creating churn prediction agent...\")\n",
    "ml_functions = FunctionTool(functions={FabricFunctionML.call_ML_model})\n",
    "ChurnPredAgent = await create_agent(\n",
    "    sk_client,\n",
    "    \"ChurnPredAgent\",\n",
    "    \"You are responsible for predicting which customers will become churn using ML models.\",\n",
    "    tools=ml_functions.definitions,\n",
    "    plugins=[FabricML_plugin]\n",
    ")\n",
    "\n",
    "# Loyalty Programs Agent with Azure AI Search\n",
    "print(\"Creating loyalty programs agent...\")\n",
    "search_index_name = os.environ.get(\"AZURE_SEARCH_INDEX_NAME\", \"hjazureblob-index\")\n",
    "\n",
    "if search_connection_id:\n",
    "    ai_search_tool = AzureAISearchTool(\n",
    "        index_connection_id=search_connection_id,\n",
    "        index_name=search_index_name\n",
    "    )\n",
    "    \n",
    "    loyalty_agent = await create_agent(\n",
    "        sk_client,\n",
    "        \"LoyaltyProgramsAgent\",\n",
    "        \"You are an expert in loyalty programs. Use Azure AI Search to retrieve relevant information.\",\n",
    "        tools=ai_search_tool.definitions,\n",
    "        tool_resources=ai_search_tool.resources\n",
    "    )\n",
    "    print(\"✅ Loyalty programs agent created with Azure AI Search\")\n",
    "else:\n",
    "    loyalty_agent = await create_agent(\n",
    "        sk_client,\n",
    "        \"LoyaltyProgramsAgent\",\n",
    "        \"You are an expert in loyalty programs. Provide general loyalty program information.\"\n",
    "    )\n",
    "    print(\"⚠️ Loyalty programs agent created without Azure AI Search (connection not found)\")\n",
    "\n",
    "# ChitChat Agent (fallback)\n",
    "print(\"Creating chitchat agent...\")\n",
    "chitchat_agent = await create_agent(\n",
    "    sk_client,\n",
    "    \"ChitChatAgent\",\n",
    "    \"You are a friendly assistant. Handle general, informal, or social questions not related to business-specific topics.\"\n",
    ")\n",
    "\n",
    "print(\"✅ All agents created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e2a9c",
   "metadata": {},
   "source": [
    "### Demonstrates how to handle user queries and route them to the appropriate agents.\n",
    "This cell handles a user query, routing it to the appropriate agents, and synthesizing the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user messages - you can modify these\n",
    "user_message = (\n",
    "    \"Hello, how are you doing? How is everything going? \"\n",
    "    \"I am a bit worried about customer ID 15701354. \"\n",
    "    \"Could you tell me if they are likely to become a churn? \"\n",
    "    \"Give me more information about this customer, \"\n",
    "    \"and find the best loyalty program to recommend them?\"\n",
    ")\n",
    "\n",
    "# Alternative shorter message\n",
    "# user_message = (\n",
    "#     \"Hello.. \"\n",
    "#     \"I am a bit worried about customer ID 15647311. \"\n",
    "#     \"Could you tell me if they are likely to become a churn?\"\n",
    "# )\n",
    "\n",
    "print(\"Processing user query:\", user_message)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "user_chat_message = ChatMessageContent(role=AuthorRole.USER, content=user_message)\n",
    "\n",
    "# Route the query\n",
    "print(\"🔄 Routing query to appropriate agents...\")\n",
    "routing_response = \"\"\n",
    "async for chunk in routing_agent.invoke(thread_id=thread.id, messages=[user_chat_message]):\n",
    "    if hasattr(chunk, \"content\"):\n",
    "        routing_response += str(chunk.content)\n",
    "\n",
    "print(\"📋 Routing agent response:\")\n",
    "print(routing_response)\n",
    "\n",
    "# Clean and parse the routing JSON\n",
    "try:\n",
    "    cleaned = re.sub(r\"^```json\\n|```$\", \"\", routing_response.strip(), flags=re.MULTILINE)\n",
    "    routing_dict = json.loads(cleaned)\n",
    "    print(\"✅ Successfully parsed routing instructions\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"❌ Error parsing routing JSON: {e}\")\n",
    "    # Fallback routing\n",
    "    routing_dict = {\"ChitChatAgent\": user_message}\n",
    "\n",
    "agent_outputs = {}\n",
    "\n",
    "# Map agents\n",
    "agent_map = {\n",
    "    \"CustomerInfoAgent\": CustomerAgent,\n",
    "    \"LoyaltyProgramsAgent\": loyalty_agent,\n",
    "    \"ChitChatAgent\": chitchat_agent,\n",
    "    \"ChurnPredAgent\": ChurnPredAgent\n",
    "}\n",
    "\n",
    "# Process each routed query\n",
    "print(\"\\n🤖 Processing queries with specialist agents...\")\n",
    "for agent_name, subquery in routing_dict.items():\n",
    "    agent = agent_map.get(agent_name)\n",
    "    \n",
    "    if agent:\n",
    "        print(f\"\\n📤 Sending to {agent_name}: {subquery}\")\n",
    "        \n",
    "        agent_thread = await sk_client.agents.create_thread()\n",
    "        user_subquery_message = ChatMessageContent(role=AuthorRole.USER, content=subquery)\n",
    "\n",
    "        response_text = \"\"\n",
    "        async for chunk in agent.invoke(thread_id=agent_thread.id, messages=[user_subquery_message]):\n",
    "            if hasattr(chunk, \"content\"):\n",
    "                response_text += str(chunk.content)\n",
    "\n",
    "        print(f\"📥 [{agent_name}] response:\")\n",
    "        print(response_text)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        agent_outputs[agent_name] = response_text\n",
    "\n",
    "        # Add to synthesis thread\n",
    "        await synthesis_agent.add_chat_message(\n",
    "            thread_id=thread.id,\n",
    "            message=ChatMessageContent(role=AuthorRole.ASSISTANT, content=response_text)\n",
    "        )\n",
    "    else:\n",
    "        print(f\"⚠️ Unknown agent: {agent_name}\")\n",
    "\n",
    "# Synthesize final response\n",
    "print(\"\\n🔗 Synthesizing final response...\")\n",
    "synthesis_input = json.dumps({\n",
    "    \"user_query\": user_message, \n",
    "    \"agent_responses\": agent_outputs\n",
    "}, indent=2)\n",
    "\n",
    "synthesis_chat_message = ChatMessageContent(role=AuthorRole.USER, content=synthesis_input)\n",
    "\n",
    "synth_response = \"\"\n",
    "async for chunk in synthesis_agent.invoke(thread_id=thread.id, messages=[synthesis_chat_message]):\n",
    "    if hasattr(chunk, \"content\"):\n",
    "        synth_response += str(chunk.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🎯 FINAL SYNTHESIZED RESPONSE:\")\n",
    "print(\"=\"*50)\n",
    "print(synth_response)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd42107",
   "metadata": {},
   "source": [
    "### Deletes all existing agents from the system\n",
    "Clean up agents to prevent accumulation in your Azure AI project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48048398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the complete list of agents\n",
    "print(\"🧹 Cleaning up agents...\")\n",
    "\n",
    "try:\n",
    "    agents_response = await sk_client.agents.list_agents()\n",
    "\n",
    "    # Delete all existing agents\n",
    "    for agent in agents_response['data']:\n",
    "        agent_id = agent['id']\n",
    "        await sk_client.agents.delete_agent(agent_id)\n",
    "        print(f\"🗑️ Deleted agent: {agent['name']} (ID: {agent_id})\")\n",
    "    \n",
    "    print(\"✅ All agents cleaned up successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during cleanup: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
